---
title: "Vignette for hdiAnalysis"
author: "Andrew Edwards"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette for hdiAnalysis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
date: "Last rendered on `r format(Sys.time(), '%d %B, %Y')`"
---

<!-- To build either run
rmarkdown::render("hdiAnalysis-vignette.Rmd")
 or click the knit button in RStudio -->


```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 6
)
```

THIS was before the switch to doing `density = FALSE`, and was used as template
for more concise `results.Rmd` vignette. Keeping for now as have not used the
Issues code etc. towards the end, and there may be something useful here. But
probably not needed for manuscript.

# Investigating the issues we came across

## Issue 1 -- trying the default HDInterval options that is not based on density kernel

Explain (see Extended Methods).

```{r nodensity}
res_2021_no_density <- create_intervals(rec_2021,
                                        density = FALSE)
res_2021_no_density
res_2021_no_density$intervals %>% a()
```
Our code just uses the `HDInterval::hdi()` method, as confirmed here:
```{r nodensitycheck}
expect_equal(c(res_2021_no_density$intervals$hdi_lower,
               res_2021_no_density$intervals$hdi_upper),
             as.numeric(HDInterval::hdi(rec_2021)))
```


The density was calculated here but only for plotting purposes, and is the same
as above:
```{r nodensity1a}
expect_equal(res_2021_no_density$dens, res_2021$dens)
```

Also there is no `height` value because that was not used when calculating the
HDI.

The equivalent plot to our Fig. 1B for the calculated HDI is
```{r no_densityplot}
plot(res_2021_no_density,
     xlim = c(0,40),
     xlab = "Recruitment (billions of age-0 fish)")
```
But, as can be seen, the heights of the two endpoints of the HDI are not the
same, with the right-hand one being lower.

Furthermore, the integral over the
HDI is only 94.5%, not the theoretical 95%:
```{r nodensity4}
integrate_simpsons(res_2021_no_density$density,
                   domain = c(as.numeric(res_2021_no_density$intervals$hdi_lower),
                              as.numeric(res_2021_no_density$intervals$hdi_upper)))
```
This is what led us to investigate the other options.

The values of the HDI calculated using density and not using density are
different:
```{r nodensity5}
res_2021$intervals %>% dplyr::select(hdi_lower, hdi_upper)
res_2021_no_density$intervals %>% dplyr::select(hdi_lower, hdi_upper) %>% a()
```

Also try `coda::HPDinterval()`, as recommended in `emdbook::tcredint()` from Ben
Bolker's book.
```{r coda}
res_2021_coda <- coda::HPDinterval(coda::as.mcmc(rec_2021))
res_2021_coda
# Compared to:
res_2021$intervals %>% dplyr::select(hdi_lower, hdi_upper)
```
which are also the same as ours using `HDInterval::hdi()`:
```{r codacheck}
expect_equal(as.numeric(res_2021_coda),
             as.numeric(HDInterval::hdi(rec_2021)))
```

## Issue 2 - default kernel density approach did not quite work

The default of 512 equally spaced points (`n`) at which to compute the kernal density
estimate in the `density()` function, did not yield satisfactory
HDIs. Setting the number of points to 512 here shows this, giving a warning
(from our `create_intervals()` function  that the densities at the HDI lower and
upper values are not within a tolerance of 1% of each other, and the difference
can be seen in the plot:
```{r n512}
res_2021_n_512 <- create_intervals(rec_2021,
                                   n = 512)
plot(res_2021_n_512,
     xlim = c(0, 40))
```

We found that increasing `n` to 100,000 gave satisfactory results. Note that
increasing `n` does not increase the wiggliness of the kernel density estimate,
just the number of points at which it is calculated.

However, the integral of the density across this HDI with 512 points was the
correct 95%:
```{r n512integral}
integrate_simpsons(res_2021_n_512$density,
                   domain = c(as.numeric(res_2021_n_512$intervals$hdi_lower),
                              as.numeric(res_2021_n_512$intervals$hdi_upper)))
```

We also experimented with other `density()` settings, such as `adjust` and `bw`,
but the defaults were satisfactory.

## Issue 3 - zeros TODO

Have to figure out the options to use now, as the defaults changed.

After incorporating Issues 1 and 2,

We found that stil

With no `from` specified, we can get negative lower bounds of the HDI for recruitment:
```{r zeroissue}
res_all_years_from_null <- create_intervals(dplyr::select(hake_recruitment_mcmc,
                                                          -c("Virgin", "1975")),
                                            from = NULL,
                                            allow_hdi_zero = TRUE)

# TODO figure out the 1975 error, to do with i_hdi_lower, think I should not
# have the ==
# Testing as get error
#res_all_years_from_null <- create_intervals(dplyr::select(hake_recruitment_mcmc,
#                                                          "1975"),
#                                            from = NULL,
#                                           allow_hdi_zero = TRUE)

res_all_years_from_null$intervals_all
sum(res_all_years_from_null$intervals_all$hdi_lower < 0)
```

Then, setting `from = 0` in `density()` prevents this, yet leads to the lower
bound of the HDI often being 0:

```{r checknonzero}
res_all_years_allow_hdi_zero <- create_intervals(dplyr::select(hake_recruitment_mcmc,
                                                               -"Virgin"),
                                                 allow_hdi_zero = TRUE)

filter(res_all_years_allow_hdi_zero$intervals_all,
       hdi_lower == 0)

years_zero <- filter(res_all_years_allow_hdi_zero$intervals_all,
                     hdi_lower == 0)$quantity

# Check the zero years remaining calculationsa are the same
expect_equal(filter(res_all_years$intervals_all,
                    quantity %in% years_zero) %>%
             select(quantity, median, eti_lower, eti_upper),
             filter(res_all_years_allow_hdi_zero$intervals_all,
                    quantity %in% years_zero) %>%
             select(quantity, median, eti_lower, eti_upper))
```

But


## Investigate warnings regarding split intervals

The function `HDInterval::hdi()` gives a warning "The HDI is discontinuous but
allowSplit = FALSE; the result is a valid CrI but not HDI." The `intervals`
output from `create_intervals()` has a column `warning` that is `TRUE` if this
occurs; for example
```{r warning1}
res_2024$intervals %>% a()
```

This can be investigated using the plotting function, to check that there is
just a small region outside of the HDI that does in fact have a higher density
than some values inside the HDI, which is due to the density approximation being
slightly wiggly. This occurs for `res_2024` calculated above, and setting
`show_discontinuity = TRUE` plots points showing the region in question. These
can barely be seen in the default plot, so we then hone in on the region in
question, seeing that, indeed, it is only a small region and not something to
get overly concerned about.
```{r, warning2, fig.height = 12}
par(mfrow = c(2,1))
plot(res_2024, show_discontinuity = TRUE)

plot(res_2024,
     show_discontinuity = TRUE,
     xlim = c(0, 25),
     ylim = c(0, 0.1))
```

For the recruitments for all years, the following have the warning during the
calculation:
```{r warning3}
years_with_warning <- dplyr::filter(res_all_years$intervals_all,
                                    warning == TRUE)$quantity
years_with_warning
expect_equal(years_with_warning,
             c(1975, 2023, 2024))   # Change some of the following if get an error
```

The plots for 1975 and 2023 show similar unconcerning behaviour to that for
2024:
```{r warning4, fig.height = 12}
par(mfrow = c(2, 1))

plot(res_all_years$res_all[[which(res_all_years$intervals_all$quantity == 1975)]],
     show_discontinuity = TRUE)

plot(res_all_years$res_all[[which(res_all_years$intervals_all$quantity == 2023)]],
     show_discontinuity = TRUE,
     xlim = c(0, 25),
     ylim = c(0, 0.1))
```

Note that the 2023 and 2024 recruitments have no data to inform them and so
are essentially samples from the prior distribution used in the assessment.

So we recommend checking the plots to see that any such behaviour is
acceptable. The "HDI is discontinuous ..." warning does not get printed, but if
another warning occurs in the `HDInterval::hdi()` calculation then that will be
shown, along with "New type of warning in create_intervals().", which should be
likely be investigated.




TODO still

Deal with warnings, which are mine in `create_intervals()`. Just do 1966

NOT SURE IF THIS IS NEEDED, maybe as another example of warnings. Maybe plot
anything from earlier that had a warning. TODO

```{r warn}
res_2024_allow_hdi_zero <- create_intervals(select(hake_recruitment_mcmc, "2024") %>% pull(), allow_hdi_zero = TRUE)

res_2024_allow_hdi_zero$intervals %>% a()

res_2024 <- create_intervals(select(hake_recruitment_mcmc, "2024") %>% pull())

res_2024$intervals %>% a()

res_2024_allow_neg <- create_intervals(select(hake_recruitment_mcmc, "2024") %>%
                                         pull(),
                                       from = -2)

res_2024_allow_neg$intervals %>% a()
# HDI goes -ve, but allowing it to.

plot(res_2024_allow_neg, xlim = c(-2, 20))

# This should give the same, except allow_hdi_zero value. Yes it is, just
# commenting as it gives error for that one change
res_2024_allow_neg_allow_zero <- create_intervals(select(hake_recruitment_mcmc, "2024") %>%
                                                  pull(),
                                                  from = -2,
                                                  allow_hdi_zero = TRUE)

# expect_equal(res_2024_allow_neg$intervals,
#              res_2024_allow_neg_allow_zero$intervals)


# Prob don't need all this. Tidy up.
res_1966 <- create_intervals(select(hake_recruitment_mcmc, "1966") %>% pull())

# Might not have redone all these
expect_equal(min(select(hake_recruitment_mcmc, "2024")),
             as.numeric(res_2024$intervals$"hdi_lower"))
```



This is old and may not be needed any more as defaults changed:

The equivalent table for HDIs would instead be TODO adapt this to show a few
years, highlighting the zero issue
```{r hakemcmc8}
res_all_years$intervals_all %>%
  dplyr::select(hdi_lower, hdi_upper) %>%
  a() %>%
  round(3) * 1000
```


## Quick long chain, but easiest to just re-run vignette with long chain results used instead

Somewhere, check the longer chain, not sure if including in package (could do if
needed, or just save these calculations somewhere else and state we did them -
would really be redoing the vignette with longer chain. Do quick calcs here
while writing appendix
```{r longchain}
rec_2021_long <- dplyr::pull(hake_recruitment_mcmc_14_long,
                             "2021")

res_2021_long <- create_intervals(rec_2021_long)

res_2021_long_no_density <- create_intervals(rec_2021_long,
                                             density = FALSE)

res_2021_long$intervals %>% a()
res_2021_long_no_density$intervals %>% a()
# NOTE values change anyway, including median, so gets hard to compare with
# original
```

Do the plot:
```{r res2021longplot}
plot(res_2021_long_no_density,
     type = "hdi",
     xlim = c(0, 40),
     ylim = c(0, 0.11),
     interval_arrows = TRUE,
     xlab = "Recruitment (billions of age-0 fish)",
     arrowhead_gap = 0.1)
```
